 I am an Eletrical Engineering Ph.D. student at North Carolina State University. I work with [Dr. Edgar Lobaton](http://www.ece.ncsu.edu/people/ejlobato/) at [Active Robotic Sensing (ARoS) Laboratory](http://research.ece.ncsu.edu/aros//) on computer vision and machine learning.


## <i class="fa fa-chevron-right"></i> Education

<table class="table table-hover">
  <tr>
    <td class="col-md-3">Aug 2011 - Present</td>
    <td>
        <strong>Ph.D. in Eletrical Engineering</strong>
        <br>
      North Carolina State University
    </td>
  </tr>
  <tr>
    <td class="col-md-3">Aug 2008 - May 2011</td>
    <td>
        <strong>M.S. in Eletrical Engineering</strong>
        <br>
      University of Electronic Science and Technology of China
    </td>
  </tr>
  <tr>
    <td class="col-md-3">Aug 2004 - May 2008</td>
    <td>
        <strong>B.S. in Eletrical Engineering</strong>
        <br>
      University of Electronic Science and Technology of China
    </td>
  </tr>
</table>


## <i class="fa fa-chevron-right"></i> Skills
<table class="table table-hover">
<tr>
  <td class='col-md-2'>Languages</td>
  <td markdown="1">
Python, MATLAB, C/C++, LaTeX
  </td>
</tr>
<tr>
  <td class='col-md-2'>Frameworks/Toolbox</td>
  <td markdown="1">
TensorFlow, NumPy, SciPy, scikit-learn, OpenCV
  </td>
</tr>
<!-- <tr>
  <td class='col-md-2'>Systems</td>
  <td markdown="1">
Linux, OSX
  </td>
</tr> -->
</table>


## <i class="fa fa-chevron-right"></i> Selected Projects
<table class="table table-hover">
<tr>
<td class="col-md-3"><a><img src='images/projects/deepvision.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>A TensorFlow API for Deep Learning based Computer Vision Algorithms (TensorCV)</strong><br>
    It is a high-level deep learning API for computer vision algorithms built on top of TensorFlow. This package is design for fast implementation of deep learning based computer vision algorithms and practice of object oriented programming. New features are continually added based on the new algorithms I am implementing.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#deepvision").toggle()'>details</a>] [<a href='http://github.com/conan7882/DeepVision-tensorflow' target='_blank'>code</a>] <br>
    
<div id="deepvision" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>A set of dataflow API to load different types of image date and dataset.</li> <li>A set of callbacks can be used for moniter and inspect training and testing process.</li> <li>summery</li> <li>save test data</li> <li>Some commonly used models, including VGG, DCGAN, are ready to use.</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/cnnviz.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Visualization of Convolutional Neural Networks</strong><br>
    TensorFlow implementations of visualizatin of CNN, such as Class Activation Mapping (CAM), Gradient-CAM and Guided Back Propagation. The aim of this project is to demostrate the visulization algorithms as well as to inspect what CNNs have leart from from large number of images.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#cnnviz").toggle()'>details</a>] [<a href='http://github.com/conan7882/CNN-Visualization' target='_blank'>code</a>] <br>
    
<div id="cnnviz" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Visulization of VGG19 attentions for different image classes using CAM, Grad-CAM and Guided back propagation.</li> <li>API</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/styletrans.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Art Style Transfer</strong><br>
    TensorFlow implementation of art style transfer using deep neural networks.<br>
    
    [<a href='http://github.com/conan7882/art_style_transfer_TensorFlow' target='_blank'>code</a>] <br>
    
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/tensorproj.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Other TensorFlow Projects</strong><br>
    There are some other projects based on TensorFlow framework, including<br>
    
<div>
<ul> 
    <li>Implementation of Deep Convolutional Generative Adversarial Networks and experiments on MNIST and CIFAR10 dataset [<a href='http://github.com/conan7882/tensorflow-DCGAN' target='_blank'>code</a>] </li> <li>Fully Convolutional Network for image segmentation [<a href='http://github.com/conan7882/tensorflow-FCN' target='_blank'>code</a>] </li> <li>Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG) [<a href='http://github.com/conan7882/VGG-tensorflow' target='_blank'>code</a>] </li>
</ul>
</div>
    <br>
    
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/courseproj.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Selected Course Projects</strong><br>
    I have done several course projects at NCSU, including<br>
    
<div>
<ul> 
    <li>Leaf classification based on visual features using PCA and k-means (2011) </li> <li>Face recognition based on eigenface using multilayer perceptron (MLP) (2012) </li> <li>Human activity recognition using hidden Markov model (HMM) (2015) </li>
</ul>
</div>
    <br>
    
</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Research Experience
<table class="table table-hover">
<tr>
<td class="col-md-3"><a><img src='images/projects/forams.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>A Visual System for Autonomous Foraminifera Identification</strong><br>
    Foraminifera (forams) are single-celled marine organisms, which are usually less than 1 mm in diameter.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#forams").toggle()'>details</a>] [<a href='https://research.ece.ncsu.edu/aros/foram-identification/' target='_blank'>web</a>] <br>
    
<div id="forams" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Developed a coarse-to-fine edge detection strategy to detect blurred and low quality edges between forams chambers with similar texture by using random forest and deep neural networks.</li> <li>This approach is able to achieve a high accuracy (88%) with a small training set.</li> <li>Leaded the creation of a forams image dataset which contains 1437 forams samples.</li> <li>Currently working on robust forams segmentation by combining deep neural networks and topological data analysis.</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/consensus.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Consensus-Based Image Segmentation</strong><br>
    The objective of this research is the development of a mathematical framework that enables the identification, characterization and matching of patterns in imaging data with certain guarantees.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#consensus").toggle()'>details</a>] [<a href='https://research.ece.ncsu.edu/aros/project/pattern-analysis/' target='_blank'>web</a>] <br>
    
<div id="consensus" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Developed a consensus-based image segmentation method through topological persistence, which is robust to parameter selection.</li> <li>Modeled a probabilistic image segmentation to represent the probability of a segmentation curve being present in a segmentation set.</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/car.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Autonomous Car</strong><br>
    The objective of this research is the development of a mathematical framework that enables the identification, characterization and matching of patterns in imaging data with certain guarantees.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#car").toggle()'>details</a>] <br>
    
<div id="car" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Improved the robustness of obstacle segmentation in outdoor scenes by using topological persistence analysis on an obstacle probability map.</li> <li>Computed the semantic segmentation of outdoor scenes based on the robust obstacle segmentation and visual features using Markov random field (MRF).</li> <li>Tracking</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/registration.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Image Registration based on Robust Topological Features</strong><br>
    The objective of this research is the development of a mathematical framework that enables the identification, characterization and matching of patterns in imaging data with certain guarantees.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#registration").toggle()'>details</a>] <br>
    
<div id="registration" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Designed an image registration algorithm under bounded non-rigid deformation which guarantees the correct matchings within a certain region.</li> <li>Computed an uncertainty map of the registration to indicate the accuracy of the registration for each pixel.</li>
</ul>
</div>
</td>
</tr>
<tr>
<td class="col-md-3"><a><img src='images/projects/newspaper.png'  onerror="this.onerror=null;this.src='images/projects/alt.jpg';"/></a> </td>
<td>
    <strong>Exploring Victorian Illustrated Newspapers Data through Computer Vision Techniques</strong><br>
    The objective of this research is the development of a mathematical framework that enables the identification, characterization and matching of patterns in imaging data with certain guarantees.<br>
    
    
[<a href='javascript: none' 
    onclick='$("#newspaper").toggle()'>details</a>] [<a href='https://ncna.dh.chass.ncsu.edu/' target='_blank'>web</a>] <br>
    
<div id="newspaper" style="text-align: justify; display: none" markdown="1">
<ul> 
    <li>Designed a visual feature for classification of line engravings and halftone images in nineteenth-century British newspapers.</li> <li>Clustered and extracted specific scenes such as portraits, crowds, buildings and weather charts using k-means, KNN and SVM based on GIST descriptor.</li>
</ul>
</div>
</td>
</tr>
</table>


## <i class="fa fa-chevron-right"></i> Selected Publications 

<!-- <a href="https://github.com/bamos/cv/blob/master/publications/conference.bib"><i class="fa fa-code-fork" aria-hidden="true"></i></a> -->

<!-- <a href="https://scholar.google.com/citations?user=" class="btn btn-primary" style="padding: 0.3em;">
  <i class="ai ai-google-scholar"></i> Google Scholar
</a> -->

<table class="table table-hover">

<tr>
<td>
    <strong>Obstacle Detection in Outdoor Scenes based on Multi-Valued Stereo Disparity Maps</strong><br>
    <strong>Q. Ge</strong> and E. Lobaton<br>
    IEEE Symp. Series Comput. Intell. (SSCI) 2017<br>
    [1] 
[<a href='javascript: none'
    onclick='$("#abs_qian2017car").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/qian-ssci2017-car.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_qian2017car" style="text-align: justify; display: none" markdown="1">
In this paper, we propose a methodology for robust obstacle detection in outdoor scenes for autonomous driving applications using a multi-valued stereo disparity approach. Traditionally, disparity maps computed from stereo pairs only provide a single estimated disparity value for each pixel. However, disparity computation suffers heavily from reflections, lack of texture and repetitive patterns of objects. This may lead to wrong estimates, which can introduce some bias on obstacle detection approaches that make use of the disparity map. To overcome this problem, instead of a single-valued disparity estimation, we propose making use of multiple candidates per pixel. The candidates are selected from a statistical analysis that characterizes the performance of the underlying matching cost function based on two metrics: The number of candidates extracted, and the distance from these candidates to the true disparity value. Then, we construct an aggregate occupancy map in u-disparity space from which obstacle detection is obtained. Experiments show that our approach can recover the correct structure of obstacles on the scene when traditional estimation approaches fail.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Coarse-to-Fine Foraminifera Image Segmentation through 3D and Deep Features</strong><br>
    <strong>Q. Ge</strong>, B. Zhong, B. Kanakiya, R. Mitra, T. Marchitto, and E. Lobaton<br>
    IEEE Symp. Series Comput. Intell. (SSCI) 2017<br>
    [2] 
[<a href='javascript: none'
    onclick='$("#abs_qian2017foramsseg").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/qian-ssci2017-foramsseg.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_qian2017foramsseg" style="text-align: justify; display: none" markdown="1">
Foraminifera are single-celled marine organisms, which are usually less than 1 mm in diameter. One of the most common tasks associated with foraminifera is the species identification of thousands of foraminifera contained in rock or ocean sediment samples, which can be a tedious manual procedure. Thus an automatic visual identification system is desirable. Some of the primary criteria for foraminifera species identification come from the characteristics of the shell itself. As such, segmentation of chambers and apertures in foraminifera images would provide powerful features for species identifica- tion. Nevertheless, none of the existing image-based, automatic classification approaches make use of segmentation, partly due to the lack of accurate segmentation methods for foraminifera images. In this paper, we propose a learning-based edge detection pipeline, using a coarse-to-fine strategy, to extract the vague edges from foraminifera images for segmentation using a relatively small training set. The experiments demonstrate our approach is able to segment chambers and apertures of foraminifera correctly and has the potential to provide useful features for species identification and other applications such as morphological study of foraminifera shells and foraminifera dataset labeling.
</div>

</td>
</tr>


<tr>
<td>
    <strong>A Comparative Study of Image Classification Algorithms for Foraminifera Identification</strong><br>
    B. Zhong, <strong>Q. Ge</strong>, B. Kanakiya, R. Mitra, T. Marchitto, and E. Lobaton<br>
    IEEE Symp. Series Comput. Intell. (SSCI) 2017<br>
    [3] 
[<a href='javascript: none'
    onclick='$("#abs_boxuan2017foramsclassify").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/boxuan-ssci2017-foramsclassify.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_boxuan2017foramsclassify" style="text-align: justify; display: none" markdown="1">
Identifying Foraminifera (or forams for short) is essential for oceanographic and geoscience research as well as petroleum exploration. Currently, this is mostly accomplished using trained human pickers, routinely taking weeks or even months to accomplish the task. In this paper, a foram identifica- tion pipeline is proposed to automatic identify forams based on computer vision and machine learning techniques. A microscope based image capturing system is used to collect a labelled image data set. Various popular image classification algorithms are adapted to this specific task and evaluated under various conditions. Finally, the potential of a weighted cross-entropy loss function in adjusting the trade-off between precision and recall is tested. The classification algorithms provide competitive results when compared to human experts labeling of the data set.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Consensus-Based Image Segmentation via Topological Persistence</strong><br>
    <strong>Q. Ge</strong> and E. Lobaton<br>
    IEEE Conf. on Comput. Vis. Pattern Recognit. Workshops (CVPRW) 2016<br>
    [4] 
[<a href='javascript: none'
    onclick='$("#abs_qian2016consensus").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/qian-cvprw2017-consensus.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_qian2016consensus" style="text-align: justify; display: none" markdown="1">
Image segmentation is one of the most important low- level operation in image processing and computer vision. It is unlikely for a single algorithm with a fixed set of param- eters to segment various images successfully due to varia- tions between images. However, it can be observed that the desired segmentation boundaries are often detected more consistently than other boundaries in the output of state- of-the-art segmentation results. In this paper, we propose a new approach to capture the consensus of information from a set of segmentations generated by varying param- eters of different algorithms. The probability of a segmen- tation curve being present is estimated based on our proba- bilistic image segmentation model. A connectivity probabil- ity map is constructed and persistent segments are extracted by applying topological persistence to the probability map. Finally, a robust segmentation is obtained with the detec- tion of certain segmentation curves guaranteed. The ex- periments demonstrate our algorithm is able to consistently capture the curves present within the segmentation set.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Robust Multi-Target Tracking in Outdoor Traffic Scenarios via Persistence Topology based Robust Motion Segmentation</strong><br>
    S. Chattopadhyay, <strong>Q. Ge</strong>, C. Wei, and E. Lobaton<br>
    IEEE Global Conf. Signal Inf. Process. (GlobalSIP) 2015<br>
    [5] 
[<a href='javascript: none'
    onclick='$("#abs_somrita2015car").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/somrita-globalsip2017-car.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_somrita2015car" style="text-align: justify; display: none" markdown="1">
In this paper, we present a motion segmentation based robust multi-target tracking technique for on-road obstacles. Our approach uses depth imaging information, and integrates persistence topology for segmentation and min-max network flow for tracking. To reduce time as well as computational complexity, the max flow problem is solved using a dynamic programming algorithm. We classify the sensor reading into regions of stationary and moving parts by aligning occupancy maps obtained from the disparity images and then, incorporate Kalman filter in the network flow algorithm to track the moving objects robustly. Our algorithm has been tested on several real-life stereo datasets and the results show that there is an improvement by a factor of three on robustness when comparing performance with and without the topological persistent detections. We also perform measurement accuracy of our algorithm using popular evaluation metrics for segmentation and tracking, and the results look promising.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Robust Obstacle Segmentation based on Topological Persistence in Outdoor Traffic Scenes</strong><br>
    C. Wei, <strong>Q. Ge</strong>, S. Chattopadhyay, and E. Lobaton<br>
    IEEE Symp. Series Comput. Intell. (SSCI) 2014<br>
    [6] 
[<a href='javascript: none'
    onclick='$("#abs_chunpeng2014car").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/chunpeng-ssci2014-car.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_chunpeng2014car" style="text-align: justify; display: none" markdown="1">
In this paper, a new methodology for robust seg- mentation of obstacles from stereo disparity maps in an on- road environment is presented. We first construct a probability of the occupancy map using the UV-disparity methodology. Traditionally, a simple threshold has been applied to segment obstacles from the occupancy map based on the connectivity of the resulting regions; however, this outcome is sensitive to the choice of parameter value. In our proposed method, instead of simple thresholding, we perform a topological persistence analysis on the constructed occupancy map. The topological framework hierarchically encodes all possible segmentation results as a function of the threshold, thus we can identify the regions that are most persistent. This leads to a more robust segmentation. The approach is analyzed using real stereo image pairs from standard datasets.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Manifold Learning Approach to Curve Identification with Applications to Footprint Segmentation</strong><br>
    N. Lokare, <strong>Q. Ge</strong>, W. Snyder, Z. Jewell, S. Allibhai, and E. Lobaton<br>
    IEEE Symp. Series Comput. Intell. (SSCI) 2014<br>
    [7] 
[<a href='javascript: none'
    onclick='$("#abs_namita2014footprint").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/namita-ssci2014footprint.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_namita2014footprint" style="text-align: justify; display: none" markdown="1">
Recognition of animals via images of their foot- prints is a non-invasive technique recently adopted by researchers interested in monitoring endangered species. One of the chal- lenges that they face is the extraction of features from these images, which are required for this approach. These features are points along the boundary curve of the footprints. In this paper, we propose an innovative technique for extracting these curves from depth images. We formulate the problem of identification of the boundary of the footprint as a pattern recognition problem of a stochastic process over a manifold. This methodology has other applications on segmentation of biological tissue for medical applications and tracking of extreme weather patterns. The problem of pattern identification in the manifold is posed as a shortest path problem, where the path with the smallest cost is identified as the one with the highest likelihood to belong to the stochastic process. Our methodology is tested in a new dataset of normalized depth images of tiger footprints with ground truth selected by experts in the field.
</div>

</td>
</tr>


<tr>
<td>
    <strong>Non-Rigid Image Registration under Non-Deterministic Deformation Bounds</strong><br>
    <strong>Q. Ge</strong>, N. Lokare, and E. Lobaton<br>
    10th International Symposium on Medical Information Processing and Analysis 2014<br>
    [8] 
[<a href='javascript: none'
    onclick='$("#abs_qian2014registration").toggle()'>abs</a>] [<a href='http://conan7882.github.io/data/papers/qian-sipim2014-registration.pdf' target='_blank'>pdf</a>] <br>
    
<div id="abs_qian2014registration" style="text-align: justify; display: none" markdown="1">
Image registration aims to identify the mapping between corresponding locations in an anatomic structure. Most traditional approaches solve this problem by minimizing some error metric. However, they do not quantify the uncertainty behind their estimates and the feasibility of other solutions. In this work, it is assumed that two images of the same anatomic structure are related via a Lipschitz non-rigid deformation (the registration map). An approach for identifying point correspondences with zero false-negative rate and high precision is introduced under this assumption. This methodology is then extended to registration of regions in an image which is posed as a graph matching problem with geometric constraints. The outcome of this approach is a homeomorphism with uncertainty bounds characterizing its accuracy over the entire image domain. The method is tested by applying deformation maps to the LPBA40 dataset.
</div>

</td>
</tr>


</table>


## <i class="fa fa-chevron-right"></i> Teaching Experience
<table class="table table-hover">
 <tr>
  <td class='col-md-1'>F2018</td>
  <td><strong>Neural Networks</strong> (NCSU ECE 542), TA</td>
</tr>
<tr>
  <td class='col-md-1'>F2016</td>
  <td><strong>Applications of Graphs and Graphical Models</strong> (NCSU ECE/CSC 792), TA</td>
</tr>
<tr>
  <td class='col-md-1'>F2015</td>
  <td><strong>Computer Systems Programming</strong> (NCSU ECE 209), TA</td>
</tr>
</table>
